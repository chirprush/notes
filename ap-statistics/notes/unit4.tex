\section{Probability}

Most of the starting probability stuff is simply a review of theoretical and
experimental probability, both things I'm familiar with.

\begin{blackbox}
    \begin{theorem}
        \textbf{Bayes' theorem} states that for dependent events \( A \) and \( B \), the
        probability that \( A \) occurs given \( B \), denoted \( \probability{A \given B} \) is
        \[
            \probability{A \given B} = \frac{\probability{B \given A} \cdot \probability{A}}{\probability{B}}
        .\]
    \end{theorem}
\end{blackbox}

While Bayes' theorem is quite useful, it can also help to draw out a
possibility tree to determine some conditional events.

Independence is also checked by using probabilites. If an event \( B \)
happening does not change the probability that \( B \) happens and vice versa,
obviously these events must be independent.

I know the multiplication rule pretty well both for independent and dependent
events, so there's not a whole lot of reason to write much about it. One thing
to say though is that probability has a lot of fun techniques and tricks that
can be used to tackle problems. For example, sometimes probability problems can
be solved by inverting the event and taking the complement probability. In
addition, there are some logical simplifications that can be reasoned through.
There are some really cool probability problems, especially those found in math
competitions, but I suppose we won't go too deep into theoretical probability
for this class. I'm excited for probability distributions though!

Let \( P \left( X \right) \) denote the probability of some outcome \( X \)
happening in a discrete probability distribution, and let \( A \) denote the
vector of all outcomes in the discrete probability distribution. Then, the mean, or expected value outcome, is
\[
    \mu_X = A \cdot P \left( A \right),
\]
where \( \cdot \) represents the dot product.

The variance for a discrete probability distribution of some random variable \(
X \) across the set of outcomes \( A \) is given as
\[
    \variance{X} = \sum_{X \in A} \left( X - \mu_X \right)^2 \cdot \probability{X}
.\]

The expected value operator \( \expected{X} \) is linear so long as the events
are independent. For the variance operator \( \variance{X} \), it satisfies a
slightly different rule:
\[
    \variance{X \pm Y} = \variance{X} + \variance{Y}
.\]
Note also that \( \variance{X} = \expected{\left( X - \expected{X} \right)^2} \).

\begin{blackbox}
    \begin{definition}
        A \textbf{binomial random variable} is a special type random variable
        in which we have some fixed number of independent trials that can be
        classified into one of two categories (for example: yes or no, success
        or failure, etc.).
    \end{definition}
\end{blackbox}

A common example is the number of heads or tails after flipping \( n \) coins.
The probability that we have \( k \) of one outcome after \( n \) trials is
given by
\[
    \probability{k \text{ of } n} = \binom{n}{k} p^k \left( 1 - p \right)^{n - k}
,\]
where \( p \) represents the probability of getting the outcome in one trial.
To illustrate this better, we'll look at an example.

\begin{example}
    Suppose we flip a biased coin \( 3 \) times, where each time it has a
    probability of \( 0.6 \) to land on heads and \( 0.4 \) to land on tails.
    What is the probability that we get \( k \) heads?

    Because of the small nature of this exercise, we can expand out all outcomes to demonstrate.
    \begin{center}
        \begin{tabular}{c|c}
            Number of heads & Possible sequences \\
            \hline
            \( 0 \) & TTT \\
            \( 1 \) & HTT, THT, TTH \\
            \( 2 \) & HHT, HTH, THH \\
            \( 3 \) & HHH
        \end{tabular}
    \end{center}
    We can see that we must choose \( k \) heads (or successes) from \( n \) flips and then probability of getting one of these is \( 0.6^k \cdot 0.4^{n-k} \).
\end{example}

\begin{blackbox}
    \begin{definition}
        The \textbf{10\% rule} states that if a sample size is less than or
        equal to \( 10\% \) of its population, we can assume that they're
        basically independent.
    \end{definition}
\end{blackbox}

This allows us to basically treat stuff as having a binomial or normal
distribution even if it technically doesn't.

The expected value of a binomial variable \( X \) that has a probability of "success" \( p \), with trials conducted \( n \) times is:
\[
    \expected{X} = np
.\]
The variance is
\[
    \variance{X} = n p \left( 1 - p \right)
.\]

\begin{blackbox}
    \begin{definition}
        A \textbf{geometric random variable} is very alike to a binomial random variable except that it doesn't have a fixed number of trials. A common phrasing would be: "how many trials will it take until some condition is fulfilled?"
    \end{definition}
\end{blackbox}

The mean and variance of some random geometric random variable \( X \) with
probability \( p \) of succeeding on each trial is given as follows\footnote{I
have proved this before (see the Stats pdf), but the proof for variance is a
bit long and so I'll probably skip that.}:
\begin{align*}
    \mu_X &= \frac{1}{p}, & \variance{X} = \frac{1-p}{p^2}
.\end{align*}
These can be derived from the fact that for a geometric random variable
\[
    \probability{X = i} = \left( 1 - p \right)^{i - 1} \cdot p
.\]
It is also trivial to prove that the cumulative distribution function is
\[
    \probability{X \le i} = 1 - \left( 1 - p \right)^i
.\]
